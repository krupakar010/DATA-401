{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4e50a4-fda1-48b2-8864-45663ecc14bf",
   "metadata": {},
   "source": [
    "## 1. Predict the running times of prospective Olympic sprinters given the data from the last 20 Olympics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66640a-2367-44bd-825d-a609040fda86",
   "metadata": {},
   "source": [
    "  Target variable is a continuios variable , so the model is to be regression, for this usecase we will start with simple linear regression, and based on the model performance. Wew can shift to more sophisticated models like random forest, SVM , gradient bosting models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb01d7-9b6c-47d7-92a1-90efd569bf75",
   "metadata": {},
   "source": [
    "## 2.You have more features (columns) than rows in your dataset.\n",
    "\n",
    "* Remove Irrelevant Features: Use techniques like correlation analysis or feature importance scores from models (e.g., Random Forest) to identify and remove features that do not contribute significantly to the prediction. \n",
    "* Use models that incorporate regularization (like Ridge or Lasso regression) to prevent overfitting by adding penalties for large coefficients.\n",
    "* If possible, gather more data to increase the number of rows. This is the most straightforward solution if feasible.\n",
    "* Use techniques like k-fold cross-validation to ensure that your model's performance is evaluated reliably, reducing the chance of overfitting on a small dataset.\n",
    "* Sometimes, simpler models (e.g., linear models) perform better than complex ones in situations with limited data.\n",
    "* Techniques like bagging or boosting can help mitigate overfitting by combining multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579bab2b-df4a-46eb-ae57-6435ce61cec6",
   "metadata": {},
   "source": [
    "## 3. Identify the most important characteristic for predicting the likelihood of being jailed before age 20.\n",
    "Below features most likely contribute\n",
    "* Family history\n",
    "* houshold income\n",
    "* living area\n",
    "* gender\n",
    "* aggression and medical condition\n",
    "* lving with family\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403663e-ee74-4fc2-a9ac-ec54eeda0cd3",
   "metadata": {},
   "source": [
    "## 4. Implement a filter to highlight emails that might be important to the recipient.\n",
    "* Sender: Emails from certain domains or specific email addresses (e.g., a boss or key client).\n",
    "* Keywords: Specific words or phrases in the subject or body that signal importance (e.g., \"urgent,\" \"action required\").\n",
    "* Response History: Emails that the recipient has previously engaged with (replied to or marked as important).\n",
    "* Attachments: Emails with attachments, especially if they're relevant to ongoing projects.\n",
    "* To list audiance one email or a big list\n",
    "* keywords related to promotion emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b181a-2abd-4e52-b9f8-10c5bf9d9ecc",
   "metadata": {},
   "source": [
    "## 5. You have more than 1,000 features.\n",
    "Most of the methods mentioned in @2 would work fine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb93db-a38c-4520-bebc-d4208c6dda91",
   "metadata": {},
   "source": [
    "## 6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "   This is classification , decision trees or random forest or gradient models would perform better. First start with feature selections\n",
    "   * product features and also the person purchase history will be helpful to predit it\n",
    "   * Person Features: Age, gender, location, and account age.\n",
    "   * Number of items added, total cart value, types of items, also session time spent on website.\n",
    "   * product Promotions, discounts applied, also the product trending features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ddde3-0764-4958-ade7-eb1a8aa23035",
   "metadata": {},
   "source": [
    "## 7. Your dataset dimensions are 982400x500.\n",
    "  Apply EDA and clean the data , find nulls or outliers. Either drop or normalize them. Try to run correlation and reduce the features.\n",
    "      * use models like regression or random forest which can process more data and features with ease\n",
    "      * Apply pca and reduce to less components and try to train the model\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451ff95-bac9-47d9-b42b-d4b819ac4bf7",
   "metadata": {},
   "source": [
    "## 8. Identify faces in an image.\n",
    " This is classification criteria so we can use classification models like knn, decision trees, Support Vector Machines for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b689712-63e6-4e26-9c43-7ca7633f1de5",
   "metadata": {},
   "source": [
    "## 9. Predict which of three flavors of ice cream will be most popular with boys versus girls.\n",
    "\n",
    "Target variabl eis flavor of ice cream , the feature is gender, location and other details. Start with data collection , and perform EDA and plot for boys/girls and ice cream flavor trends. Select classification model like knn, decision tree and SVM models. Train and cross validate the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2eaf40-f809-4924-a8cf-74dcb2133275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
